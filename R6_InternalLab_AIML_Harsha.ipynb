{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_InternalLab_AIML_(1).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8GoNTWXAOB8C",
        "Wt-HYFMEOB8G",
        "QxEqkQx6PpYW",
        "iIy5eNS9PpYX",
        "Un40VLElPpYc",
        "gRP_5VwFPpYf"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sb7Epo0VOB58"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fHpCNRv1OB5-",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjPO1TtiPpXi",
        "colab_type": "text"
      },
      "source": [
        "### Enable Eager Execution if you are using tensorflow 1.x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tnSsH8sNOB6F",
        "colab": {}
      },
      "source": [
        "#Enable Eager Execution\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DxJDmJqqOB6K"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FhllFLyKOB6N",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B4yQKMiJOB6R",
        "outputId": "9f0ae348-1c8d-4f8f-ce87-de643810dcaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data = pd.read_csv('/content/prices.csv')\n",
        "data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-05 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-06 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-07 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-08 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-11 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2016-01-12 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.510002</td>\n",
              "      <td>115.550003</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>116.059998</td>\n",
              "      <td>1098000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2016-01-13 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.459999</td>\n",
              "      <td>112.849998</td>\n",
              "      <td>112.589996</td>\n",
              "      <td>117.070000</td>\n",
              "      <td>949600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2016-01-14 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.510002</td>\n",
              "      <td>114.379997</td>\n",
              "      <td>110.050003</td>\n",
              "      <td>115.029999</td>\n",
              "      <td>785300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2016-01-15 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.330002</td>\n",
              "      <td>112.529999</td>\n",
              "      <td>111.919998</td>\n",
              "      <td>114.879997</td>\n",
              "      <td>1093700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2016-01-19 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.660004</td>\n",
              "      <td>110.379997</td>\n",
              "      <td>109.870003</td>\n",
              "      <td>115.870003</td>\n",
              "      <td>1523500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2016-01-20 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>109.059998</td>\n",
              "      <td>109.300003</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>111.599998</td>\n",
              "      <td>1653900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2016-01-21 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>109.730003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>110.580002</td>\n",
              "      <td>944300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2016-01-22 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>111.879997</td>\n",
              "      <td>111.949997</td>\n",
              "      <td>110.190002</td>\n",
              "      <td>112.949997</td>\n",
              "      <td>744900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2016-01-25 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>111.320000</td>\n",
              "      <td>110.120003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>114.629997</td>\n",
              "      <td>703800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2016-01-26 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>110.419998</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>107.300003</td>\n",
              "      <td>111.400002</td>\n",
              "      <td>563100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2016-01-27 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>110.769997</td>\n",
              "      <td>110.709999</td>\n",
              "      <td>109.019997</td>\n",
              "      <td>112.570000</td>\n",
              "      <td>896100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2016-01-28 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>110.900002</td>\n",
              "      <td>112.580002</td>\n",
              "      <td>109.900002</td>\n",
              "      <td>112.970001</td>\n",
              "      <td>680400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2016-01-29 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.349998</td>\n",
              "      <td>114.470001</td>\n",
              "      <td>111.669998</td>\n",
              "      <td>114.589996</td>\n",
              "      <td>749900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2016-02-01 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>112.900002</td>\n",
              "      <td>114.849998</td>\n",
              "      <td>574200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2016-02-02 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.250000</td>\n",
              "      <td>110.559998</td>\n",
              "      <td>109.750000</td>\n",
              "      <td>113.860001</td>\n",
              "      <td>694800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2016-02-03 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.379997</td>\n",
              "      <td>114.050003</td>\n",
              "      <td>109.639999</td>\n",
              "      <td>114.639999</td>\n",
              "      <td>896300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2016-02-04 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>115.709999</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>116.320000</td>\n",
              "      <td>956300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2016-02-05 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.120003</td>\n",
              "      <td>114.019997</td>\n",
              "      <td>109.709999</td>\n",
              "      <td>116.489998</td>\n",
              "      <td>997100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2016-02-08 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>113.300003</td>\n",
              "      <td>111.160004</td>\n",
              "      <td>110.459999</td>\n",
              "      <td>113.300003</td>\n",
              "      <td>1200500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2016-02-09 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>111.169998</td>\n",
              "      <td>110.650002</td>\n",
              "      <td>109.639999</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>1725200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2016-02-10 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>106.730003</td>\n",
              "      <td>107.519997</td>\n",
              "      <td>106.360001</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>1946000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2016-02-11 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>105.629997</td>\n",
              "      <td>107.129997</td>\n",
              "      <td>104.110001</td>\n",
              "      <td>109.260002</td>\n",
              "      <td>1319500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2016-02-12 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>108.559998</td>\n",
              "      <td>107.839996</td>\n",
              "      <td>107.070000</td>\n",
              "      <td>109.430000</td>\n",
              "      <td>922400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2016-02-16 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>109.110001</td>\n",
              "      <td>110.769997</td>\n",
              "      <td>107.010002</td>\n",
              "      <td>111.300003</td>\n",
              "      <td>1185100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2016-02-17 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>110.830002</td>\n",
              "      <td>111.239998</td>\n",
              "      <td>107.970001</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>921500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229358</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>AZO</td>\n",
              "      <td>333.579987</td>\n",
              "      <td>329.670013</td>\n",
              "      <td>329.100006</td>\n",
              "      <td>334.200012</td>\n",
              "      <td>263400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229359</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BA</td>\n",
              "      <td>70.459999</td>\n",
              "      <td>70.169998</td>\n",
              "      <td>69.830002</td>\n",
              "      <td>71.129997</td>\n",
              "      <td>6034800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229360</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BAC</td>\n",
              "      <td>5.840000</td>\n",
              "      <td>5.590000</td>\n",
              "      <td>5.530000</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>286031100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229361</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BAX</td>\n",
              "      <td>50.499999</td>\n",
              "      <td>49.479999</td>\n",
              "      <td>49.389998</td>\n",
              "      <td>50.659997</td>\n",
              "      <td>7978100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229362</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BBBY</td>\n",
              "      <td>62.299999</td>\n",
              "      <td>61.970001</td>\n",
              "      <td>61.880001</td>\n",
              "      <td>62.720001</td>\n",
              "      <td>2460200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229363</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BBT</td>\n",
              "      <td>23.580000</td>\n",
              "      <td>23.059999</td>\n",
              "      <td>22.980000</td>\n",
              "      <td>23.650000</td>\n",
              "      <td>4824600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229364</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BBY</td>\n",
              "      <td>28.049999</td>\n",
              "      <td>27.420000</td>\n",
              "      <td>27.330000</td>\n",
              "      <td>28.510000</td>\n",
              "      <td>5906900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229365</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BCR</td>\n",
              "      <td>85.699997</td>\n",
              "      <td>84.120003</td>\n",
              "      <td>84.019997</td>\n",
              "      <td>85.860001</td>\n",
              "      <td>539500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229366</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BDX</td>\n",
              "      <td>73.070000</td>\n",
              "      <td>72.529999</td>\n",
              "      <td>72.410004</td>\n",
              "      <td>73.519997</td>\n",
              "      <td>2026200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229367</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BEN</td>\n",
              "      <td>99.240005</td>\n",
              "      <td>96.480000</td>\n",
              "      <td>96.070004</td>\n",
              "      <td>99.270000</td>\n",
              "      <td>5393700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229368</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BHI</td>\n",
              "      <td>50.349998</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>48.770000</td>\n",
              "      <td>51.820000</td>\n",
              "      <td>7989300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229369</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BIIB</td>\n",
              "      <td>111.320000</td>\n",
              "      <td>109.709999</td>\n",
              "      <td>109.519997</td>\n",
              "      <td>111.900002</td>\n",
              "      <td>855800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229370</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BK</td>\n",
              "      <td>19.809999</td>\n",
              "      <td>19.059999</td>\n",
              "      <td>18.969999</td>\n",
              "      <td>19.809999</td>\n",
              "      <td>9383100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229371</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BLK</td>\n",
              "      <td>172.649994</td>\n",
              "      <td>167.500000</td>\n",
              "      <td>167.130005</td>\n",
              "      <td>172.889999</td>\n",
              "      <td>715000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229372</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BLL</td>\n",
              "      <td>34.889999</td>\n",
              "      <td>34.349998</td>\n",
              "      <td>34.279999</td>\n",
              "      <td>35.020000</td>\n",
              "      <td>1008700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229373</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BMY</td>\n",
              "      <td>33.240002</td>\n",
              "      <td>33.310001</td>\n",
              "      <td>33.240002</td>\n",
              "      <td>33.660000</td>\n",
              "      <td>10612200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229374</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BSX</td>\n",
              "      <td>5.580000</td>\n",
              "      <td>5.320000</td>\n",
              "      <td>5.270000</td>\n",
              "      <td>5.620000</td>\n",
              "      <td>17497500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229375</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BWA</td>\n",
              "      <td>69.070000</td>\n",
              "      <td>68.260002</td>\n",
              "      <td>68.029999</td>\n",
              "      <td>69.820000</td>\n",
              "      <td>2879800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229376</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>BXP</td>\n",
              "      <td>95.400002</td>\n",
              "      <td>93.790001</td>\n",
              "      <td>93.510002</td>\n",
              "      <td>95.440002</td>\n",
              "      <td>695000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229377</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>C</td>\n",
              "      <td>29.280001</td>\n",
              "      <td>27.750000</td>\n",
              "      <td>27.410000</td>\n",
              "      <td>29.350000</td>\n",
              "      <td>80314500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229378</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>CA</td>\n",
              "      <td>21.350000</td>\n",
              "      <td>20.980000</td>\n",
              "      <td>20.940001</td>\n",
              "      <td>21.510000</td>\n",
              "      <td>2784300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229379</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>CAG</td>\n",
              "      <td>25.310000</td>\n",
              "      <td>25.369999</td>\n",
              "      <td>25.310000</td>\n",
              "      <td>25.670000</td>\n",
              "      <td>3309900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229380</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>CAH</td>\n",
              "      <td>41.599998</td>\n",
              "      <td>41.290001</td>\n",
              "      <td>41.189999</td>\n",
              "      <td>41.779999</td>\n",
              "      <td>3106000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229381</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>CAT</td>\n",
              "      <td>94.339996</td>\n",
              "      <td>92.919998</td>\n",
              "      <td>92.599998</td>\n",
              "      <td>95.529999</td>\n",
              "      <td>7842300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229382</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>CB</td>\n",
              "      <td>70.239998</td>\n",
              "      <td>68.680000</td>\n",
              "      <td>68.540001</td>\n",
              "      <td>70.330002</td>\n",
              "      <td>2034700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229383</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>CBG</td>\n",
              "      <td>15.920000</td>\n",
              "      <td>15.060000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>9188600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229384</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>CBS</td>\n",
              "      <td>26.250000</td>\n",
              "      <td>25.639999</td>\n",
              "      <td>25.559999</td>\n",
              "      <td>26.270000</td>\n",
              "      <td>6672400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229385</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>CCI</td>\n",
              "      <td>43.080002</td>\n",
              "      <td>42.480000</td>\n",
              "      <td>42.240002</td>\n",
              "      <td>43.119999</td>\n",
              "      <td>1137300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229386</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>CCL</td>\n",
              "      <td>33.980000</td>\n",
              "      <td>33.430000</td>\n",
              "      <td>33.220001</td>\n",
              "      <td>34.099998</td>\n",
              "      <td>4103600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229387</th>\n",
              "      <td>2011-12-08</td>\n",
              "      <td>CELG</td>\n",
              "      <td>62.389999</td>\n",
              "      <td>61.290001</td>\n",
              "      <td>61.139999</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>229388 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       date symbol  ...        high       volume\n",
              "0       2016-01-05 00:00:00   WLTW  ...  126.250000    2163600.0\n",
              "1       2016-01-06 00:00:00   WLTW  ...  125.540001    2386400.0\n",
              "2       2016-01-07 00:00:00   WLTW  ...  119.739998    2489500.0\n",
              "3       2016-01-08 00:00:00   WLTW  ...  117.440002    2006300.0\n",
              "4       2016-01-11 00:00:00   WLTW  ...  117.330002    1408600.0\n",
              "5       2016-01-12 00:00:00   WLTW  ...  116.059998    1098000.0\n",
              "6       2016-01-13 00:00:00   WLTW  ...  117.070000     949600.0\n",
              "7       2016-01-14 00:00:00   WLTW  ...  115.029999     785300.0\n",
              "8       2016-01-15 00:00:00   WLTW  ...  114.879997    1093700.0\n",
              "9       2016-01-19 00:00:00   WLTW  ...  115.870003    1523500.0\n",
              "10      2016-01-20 00:00:00   WLTW  ...  111.599998    1653900.0\n",
              "11      2016-01-21 00:00:00   WLTW  ...  110.580002     944300.0\n",
              "12      2016-01-22 00:00:00   WLTW  ...  112.949997     744900.0\n",
              "13      2016-01-25 00:00:00   WLTW  ...  114.629997     703800.0\n",
              "14      2016-01-26 00:00:00   WLTW  ...  111.400002     563100.0\n",
              "15      2016-01-27 00:00:00   WLTW  ...  112.570000     896100.0\n",
              "16      2016-01-28 00:00:00   WLTW  ...  112.970001     680400.0\n",
              "17      2016-01-29 00:00:00   WLTW  ...  114.589996     749900.0\n",
              "18      2016-02-01 00:00:00   WLTW  ...  114.849998     574200.0\n",
              "19      2016-02-02 00:00:00   WLTW  ...  113.860001     694800.0\n",
              "20      2016-02-03 00:00:00   WLTW  ...  114.639999     896300.0\n",
              "21      2016-02-04 00:00:00   WLTW  ...  116.320000     956300.0\n",
              "22      2016-02-05 00:00:00   WLTW  ...  116.489998     997100.0\n",
              "23      2016-02-08 00:00:00   WLTW  ...  113.300003    1200500.0\n",
              "24      2016-02-09 00:00:00   WLTW  ...  112.110001    1725200.0\n",
              "25      2016-02-10 00:00:00   WLTW  ...  112.110001    1946000.0\n",
              "26      2016-02-11 00:00:00   WLTW  ...  109.260002    1319500.0\n",
              "27      2016-02-12 00:00:00   WLTW  ...  109.430000     922400.0\n",
              "28      2016-02-16 00:00:00   WLTW  ...  111.300003    1185100.0\n",
              "29      2016-02-17 00:00:00   WLTW  ...  112.110001     921500.0\n",
              "...                     ...    ...  ...         ...          ...\n",
              "229358           2011-12-08    AZO  ...  334.200012     263400.0\n",
              "229359           2011-12-08     BA  ...   71.129997    6034800.0\n",
              "229360           2011-12-08    BAC  ...    5.880000  286031100.0\n",
              "229361           2011-12-08    BAX  ...   50.659997    7978100.0\n",
              "229362           2011-12-08   BBBY  ...   62.720001    2460200.0\n",
              "229363           2011-12-08    BBT  ...   23.650000    4824600.0\n",
              "229364           2011-12-08    BBY  ...   28.510000    5906900.0\n",
              "229365           2011-12-08    BCR  ...   85.860001     539500.0\n",
              "229366           2011-12-08    BDX  ...   73.519997    2026200.0\n",
              "229367           2011-12-08    BEN  ...   99.270000    5393700.0\n",
              "229368           2011-12-08    BHI  ...   51.820000    7989300.0\n",
              "229369           2011-12-08   BIIB  ...  111.900002     855800.0\n",
              "229370           2011-12-08     BK  ...   19.809999    9383100.0\n",
              "229371           2011-12-08    BLK  ...  172.889999     715000.0\n",
              "229372           2011-12-08    BLL  ...   35.020000    1008700.0\n",
              "229373           2011-12-08    BMY  ...   33.660000   10612200.0\n",
              "229374           2011-12-08    BSX  ...    5.620000   17497500.0\n",
              "229375           2011-12-08    BWA  ...   69.820000    2879800.0\n",
              "229376           2011-12-08    BXP  ...   95.440002     695000.0\n",
              "229377           2011-12-08      C  ...   29.350000   80314500.0\n",
              "229378           2011-12-08     CA  ...   21.510000    2784300.0\n",
              "229379           2011-12-08    CAG  ...   25.670000    3309900.0\n",
              "229380           2011-12-08    CAH  ...   41.779999    3106000.0\n",
              "229381           2011-12-08    CAT  ...   95.529999    7842300.0\n",
              "229382           2011-12-08     CB  ...   70.330002    2034700.0\n",
              "229383           2011-12-08    CBG  ...   16.000000    9188600.0\n",
              "229384           2011-12-08    CBS  ...   26.270000    6672400.0\n",
              "229385           2011-12-08    CCI  ...   43.119999    1137300.0\n",
              "229386           2011-12-08    CCL  ...   34.099998    4103600.0\n",
              "229387           2011-12-08   CELG  ...   62.000000          NaN\n",
              "\n",
              "[229388 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fgkX6SEqOB6W"
      },
      "source": [
        "### Check all columns in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7K8pWsNQOB6X",
        "outputId": "79ff772c-25c6-4866-ad7c-a4dab4e224ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['date', 'symbol', 'open', 'close', 'low', 'high', 'volume'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7dU6X7MpOB6c"
      },
      "source": [
        "### Drop columns `date` and  `symbol`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lh_6spSKOB6e",
        "colab": {}
      },
      "source": [
        "data = data.drop(['date','symbol'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xlwbUgTwOB6i",
        "outputId": "c51d23ee-7b5b-4e8b-fc1a-5e681a065f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high     volume\n",
              "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
              "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
              "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
              "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
              "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3DBv3WWYOB6q"
      },
      "source": [
        "### Consider only first 1000 rows in the dataset for building feature set and target set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z_hG9rGBOB6s",
        "outputId": "98fc2904-744c-4a5c-99e5-e2ac54fd7733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data = data[:1000]\n",
        "data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>115.510002</td>\n",
              "      <td>115.550003</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>116.059998</td>\n",
              "      <td>1098000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>116.459999</td>\n",
              "      <td>112.849998</td>\n",
              "      <td>112.589996</td>\n",
              "      <td>117.070000</td>\n",
              "      <td>949600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>113.510002</td>\n",
              "      <td>114.379997</td>\n",
              "      <td>110.050003</td>\n",
              "      <td>115.029999</td>\n",
              "      <td>785300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>113.330002</td>\n",
              "      <td>112.529999</td>\n",
              "      <td>111.919998</td>\n",
              "      <td>114.879997</td>\n",
              "      <td>1093700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>113.660004</td>\n",
              "      <td>110.379997</td>\n",
              "      <td>109.870003</td>\n",
              "      <td>115.870003</td>\n",
              "      <td>1523500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>109.059998</td>\n",
              "      <td>109.300003</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>111.599998</td>\n",
              "      <td>1653900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>109.730003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>108.320000</td>\n",
              "      <td>110.580002</td>\n",
              "      <td>944300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>111.879997</td>\n",
              "      <td>111.949997</td>\n",
              "      <td>110.190002</td>\n",
              "      <td>112.949997</td>\n",
              "      <td>744900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>111.320000</td>\n",
              "      <td>110.120003</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>114.629997</td>\n",
              "      <td>703800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>110.419998</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>107.300003</td>\n",
              "      <td>111.400002</td>\n",
              "      <td>563100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>110.769997</td>\n",
              "      <td>110.709999</td>\n",
              "      <td>109.019997</td>\n",
              "      <td>112.570000</td>\n",
              "      <td>896100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>110.900002</td>\n",
              "      <td>112.580002</td>\n",
              "      <td>109.900002</td>\n",
              "      <td>112.970001</td>\n",
              "      <td>680400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>113.349998</td>\n",
              "      <td>114.470001</td>\n",
              "      <td>111.669998</td>\n",
              "      <td>114.589996</td>\n",
              "      <td>749900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>114.000000</td>\n",
              "      <td>114.500000</td>\n",
              "      <td>112.900002</td>\n",
              "      <td>114.849998</td>\n",
              "      <td>574200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>113.250000</td>\n",
              "      <td>110.559998</td>\n",
              "      <td>109.750000</td>\n",
              "      <td>113.860001</td>\n",
              "      <td>694800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>113.379997</td>\n",
              "      <td>114.050003</td>\n",
              "      <td>109.639999</td>\n",
              "      <td>114.639999</td>\n",
              "      <td>896300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>114.080002</td>\n",
              "      <td>115.709999</td>\n",
              "      <td>114.080002</td>\n",
              "      <td>116.320000</td>\n",
              "      <td>956300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>115.120003</td>\n",
              "      <td>114.019997</td>\n",
              "      <td>109.709999</td>\n",
              "      <td>116.489998</td>\n",
              "      <td>997100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>113.300003</td>\n",
              "      <td>111.160004</td>\n",
              "      <td>110.459999</td>\n",
              "      <td>113.300003</td>\n",
              "      <td>1200500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>111.169998</td>\n",
              "      <td>110.650002</td>\n",
              "      <td>109.639999</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>1725200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>106.730003</td>\n",
              "      <td>107.519997</td>\n",
              "      <td>106.360001</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>1946000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>105.629997</td>\n",
              "      <td>107.129997</td>\n",
              "      <td>104.110001</td>\n",
              "      <td>109.260002</td>\n",
              "      <td>1319500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>108.559998</td>\n",
              "      <td>107.839996</td>\n",
              "      <td>107.070000</td>\n",
              "      <td>109.430000</td>\n",
              "      <td>922400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>109.110001</td>\n",
              "      <td>110.769997</td>\n",
              "      <td>107.010002</td>\n",
              "      <td>111.300003</td>\n",
              "      <td>1185100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>110.830002</td>\n",
              "      <td>111.239998</td>\n",
              "      <td>107.970001</td>\n",
              "      <td>112.110001</td>\n",
              "      <td>921500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>970</th>\n",
              "      <td>19.240000</td>\n",
              "      <td>18.680000</td>\n",
              "      <td>18.530001</td>\n",
              "      <td>19.430000</td>\n",
              "      <td>9097500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>971</th>\n",
              "      <td>20.520000</td>\n",
              "      <td>20.290001</td>\n",
              "      <td>19.709999</td>\n",
              "      <td>20.549999</td>\n",
              "      <td>2242100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972</th>\n",
              "      <td>12.950000</td>\n",
              "      <td>13.550000</td>\n",
              "      <td>12.720000</td>\n",
              "      <td>13.600000</td>\n",
              "      <td>6205100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>973</th>\n",
              "      <td>76.059998</td>\n",
              "      <td>75.440002</td>\n",
              "      <td>75.349998</td>\n",
              "      <td>76.370003</td>\n",
              "      <td>864600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>974</th>\n",
              "      <td>19.620001</td>\n",
              "      <td>19.830000</td>\n",
              "      <td>19.480000</td>\n",
              "      <td>19.830000</td>\n",
              "      <td>709200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>975</th>\n",
              "      <td>88.000000</td>\n",
              "      <td>87.370003</td>\n",
              "      <td>87.139999</td>\n",
              "      <td>88.239998</td>\n",
              "      <td>1129600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>976</th>\n",
              "      <td>31.010000</td>\n",
              "      <td>30.959999</td>\n",
              "      <td>30.700001</td>\n",
              "      <td>31.120001</td>\n",
              "      <td>3449300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>35.900002</td>\n",
              "      <td>35.189999</td>\n",
              "      <td>34.930000</td>\n",
              "      <td>35.910000</td>\n",
              "      <td>7517100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>76.620003</td>\n",
              "      <td>77.650002</td>\n",
              "      <td>76.550003</td>\n",
              "      <td>77.790001</td>\n",
              "      <td>2356500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>979</th>\n",
              "      <td>25.799999</td>\n",
              "      <td>26.420000</td>\n",
              "      <td>25.719999</td>\n",
              "      <td>26.610001</td>\n",
              "      <td>4839200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>30.370001</td>\n",
              "      <td>31.059999</td>\n",
              "      <td>30.309999</td>\n",
              "      <td>31.110001</td>\n",
              "      <td>3684600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>981</th>\n",
              "      <td>23.120001</td>\n",
              "      <td>22.920000</td>\n",
              "      <td>22.740000</td>\n",
              "      <td>23.129999</td>\n",
              "      <td>14428400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>39.790001</td>\n",
              "      <td>39.610001</td>\n",
              "      <td>39.090000</td>\n",
              "      <td>39.799999</td>\n",
              "      <td>1463300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>24.669997</td>\n",
              "      <td>25.140004</td>\n",
              "      <td>24.669997</td>\n",
              "      <td>25.160000</td>\n",
              "      <td>749600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>11.250000</td>\n",
              "      <td>11.770000</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>11.790000</td>\n",
              "      <td>13355100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>1.630000</td>\n",
              "      <td>1.650000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>1.660000</td>\n",
              "      <td>11538300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>986</th>\n",
              "      <td>17.020000</td>\n",
              "      <td>16.860001</td>\n",
              "      <td>16.790001</td>\n",
              "      <td>17.209999</td>\n",
              "      <td>9931300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>987</th>\n",
              "      <td>257.840004</td>\n",
              "      <td>256.079998</td>\n",
              "      <td>253.050003</td>\n",
              "      <td>257.959995</td>\n",
              "      <td>12906000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>48.099998</td>\n",
              "      <td>48.150002</td>\n",
              "      <td>47.700001</td>\n",
              "      <td>48.369999</td>\n",
              "      <td>369900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>34.529999</td>\n",
              "      <td>34.430000</td>\n",
              "      <td>34.080002</td>\n",
              "      <td>34.750000</td>\n",
              "      <td>2701000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>990</th>\n",
              "      <td>27.570000</td>\n",
              "      <td>27.790001</td>\n",
              "      <td>27.370000</td>\n",
              "      <td>27.919999</td>\n",
              "      <td>2627800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>14.200000</td>\n",
              "      <td>14.420000</td>\n",
              "      <td>14.120000</td>\n",
              "      <td>14.430000</td>\n",
              "      <td>3258700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>19.900000</td>\n",
              "      <td>19.580000</td>\n",
              "      <td>19.330000</td>\n",
              "      <td>20.059999</td>\n",
              "      <td>5206100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>62.660000</td>\n",
              "      <td>62.299999</td>\n",
              "      <td>62.189999</td>\n",
              "      <td>62.750000</td>\n",
              "      <td>7099000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>29.219999</td>\n",
              "      <td>28.719999</td>\n",
              "      <td>28.629999</td>\n",
              "      <td>29.309999</td>\n",
              "      <td>7795500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>63.310001</td>\n",
              "      <td>63.590000</td>\n",
              "      <td>63.240002</td>\n",
              "      <td>63.639999</td>\n",
              "      <td>2133200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>27.160000</td>\n",
              "      <td>26.990000</td>\n",
              "      <td>26.680000</td>\n",
              "      <td>27.299999</td>\n",
              "      <td>1982400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>28.320000</td>\n",
              "      <td>28.770000</td>\n",
              "      <td>28.010000</td>\n",
              "      <td>28.809999</td>\n",
              "      <td>37152800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>44.000000</td>\n",
              "      <td>44.799999</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>44.810001</td>\n",
              "      <td>6568600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>36.080002</td>\n",
              "      <td>37.139999</td>\n",
              "      <td>36.009998</td>\n",
              "      <td>37.230000</td>\n",
              "      <td>5604300.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           open       close         low        high      volume\n",
              "0    123.430000  125.839996  122.309998  126.250000   2163600.0\n",
              "1    125.239998  119.980003  119.940002  125.540001   2386400.0\n",
              "2    116.379997  114.949997  114.930000  119.739998   2489500.0\n",
              "3    115.480003  116.620003  113.500000  117.440002   2006300.0\n",
              "4    117.010002  114.970001  114.089996  117.330002   1408600.0\n",
              "5    115.510002  115.550003  114.500000  116.059998   1098000.0\n",
              "6    116.459999  112.849998  112.589996  117.070000    949600.0\n",
              "7    113.510002  114.379997  110.050003  115.029999    785300.0\n",
              "8    113.330002  112.529999  111.919998  114.879997   1093700.0\n",
              "9    113.660004  110.379997  109.870003  115.870003   1523500.0\n",
              "10   109.059998  109.300003  108.320000  111.599998   1653900.0\n",
              "11   109.730003  110.000000  108.320000  110.580002    944300.0\n",
              "12   111.879997  111.949997  110.190002  112.949997    744900.0\n",
              "13   111.320000  110.120003  110.000000  114.629997    703800.0\n",
              "14   110.419998  111.000000  107.300003  111.400002    563100.0\n",
              "15   110.769997  110.709999  109.019997  112.570000    896100.0\n",
              "16   110.900002  112.580002  109.900002  112.970001    680400.0\n",
              "17   113.349998  114.470001  111.669998  114.589996    749900.0\n",
              "18   114.000000  114.500000  112.900002  114.849998    574200.0\n",
              "19   113.250000  110.559998  109.750000  113.860001    694800.0\n",
              "20   113.379997  114.050003  109.639999  114.639999    896300.0\n",
              "21   114.080002  115.709999  114.080002  116.320000    956300.0\n",
              "22   115.120003  114.019997  109.709999  116.489998    997100.0\n",
              "23   113.300003  111.160004  110.459999  113.300003   1200500.0\n",
              "24   111.169998  110.650002  109.639999  112.110001   1725200.0\n",
              "25   106.730003  107.519997  106.360001  112.110001   1946000.0\n",
              "26   105.629997  107.129997  104.110001  109.260002   1319500.0\n",
              "27   108.559998  107.839996  107.070000  109.430000    922400.0\n",
              "28   109.110001  110.769997  107.010002  111.300003   1185100.0\n",
              "29   110.830002  111.239998  107.970001  112.110001    921500.0\n",
              "..          ...         ...         ...         ...         ...\n",
              "970   19.240000   18.680000   18.530001   19.430000   9097500.0\n",
              "971   20.520000   20.290001   19.709999   20.549999   2242100.0\n",
              "972   12.950000   13.550000   12.720000   13.600000   6205100.0\n",
              "973   76.059998   75.440002   75.349998   76.370003    864600.0\n",
              "974   19.620001   19.830000   19.480000   19.830000    709200.0\n",
              "975   88.000000   87.370003   87.139999   88.239998   1129600.0\n",
              "976   31.010000   30.959999   30.700001   31.120001   3449300.0\n",
              "977   35.900002   35.189999   34.930000   35.910000   7517100.0\n",
              "978   76.620003   77.650002   76.550003   77.790001   2356500.0\n",
              "979   25.799999   26.420000   25.719999   26.610001   4839200.0\n",
              "980   30.370001   31.059999   30.309999   31.110001   3684600.0\n",
              "981   23.120001   22.920000   22.740000   23.129999  14428400.0\n",
              "982   39.790001   39.610001   39.090000   39.799999   1463300.0\n",
              "983   24.669997   25.140004   24.669997   25.160000    749600.0\n",
              "984   11.250000   11.770000   11.200000   11.790000  13355100.0\n",
              "985    1.630000    1.650000    1.600000    1.660000  11538300.0\n",
              "986   17.020000   16.860001   16.790001   17.209999   9931300.0\n",
              "987  257.840004  256.079998  253.050003  257.959995  12906000.0\n",
              "988   48.099998   48.150002   47.700001   48.369999    369900.0\n",
              "989   34.529999   34.430000   34.080002   34.750000   2701000.0\n",
              "990   27.570000   27.790001   27.370000   27.919999   2627800.0\n",
              "991   14.200000   14.420000   14.120000   14.430000   3258700.0\n",
              "992   19.900000   19.580000   19.330000   20.059999   5206100.0\n",
              "993   62.660000   62.299999   62.189999   62.750000   7099000.0\n",
              "994   29.219999   28.719999   28.629999   29.309999   7795500.0\n",
              "995   63.310001   63.590000   63.240002   63.639999   2133200.0\n",
              "996   27.160000   26.990000   26.680000   27.299999   1982400.0\n",
              "997   28.320000   28.770000   28.010000   28.809999  37152800.0\n",
              "998   44.000000   44.799999   43.750000   44.810001   6568600.0\n",
              "999   36.080002   37.139999   36.009998   37.230000   5604300.0\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UUPH79-PpX8",
        "colab_type": "text"
      },
      "source": [
        "### Convert Float64 to Float32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWzhwnRJPpX-",
        "colab_type": "code",
        "outputId": "b3d660ad-ae41-4ecc-98a8-b626f6567dda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "open      float64\n",
              "close     float64\n",
              "low       float64\n",
              "high      float64\n",
              "volume    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPwaK_ouUNbA",
        "colab_type": "code",
        "outputId": "001a9c5a-9f0b-4029-f1a2-04c9dc35f464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "datacopy = data.astype('float32')\n",
        "datacopy.dtypes"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "open      float32\n",
              "close     float32\n",
              "low       float32\n",
              "high      float32\n",
              "volume    float32\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M3UaApqYOB6x"
      },
      "source": [
        "### Divide the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2EkKAy7fOB6y",
        "colab": {}
      },
      "source": [
        "X = datacopy.drop('close', axis=1)\n",
        "y = datacopy['close']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf3ohY3CVZum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
        "                                                    test_size=0.2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7STKBKzKPpYD",
        "colab_type": "text"
      },
      "source": [
        "### Normalize Train and Test Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOIGSyGHPpYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler() \n",
        "X_train_transform = scaler.fit_transform(train_X) \n",
        "X_test_transform = scaler.fit_transform(test_X)\n",
        "X_train_transform = X_train_transform.astype('float32')\n",
        "X_test_transform = X_test_transform.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v6vE4eYCOB62"
      },
      "source": [
        "## Building the graph in tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "297_qja4OB7A"
      },
      "source": [
        "2.Define Weights and Bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L205qPeQOB7B",
        "colab": {}
      },
      "source": [
        "w = tf.zeros(shape=(4,1))\n",
        "b = tf.zeros(shape=(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HgtWA-UIOB7F"
      },
      "source": [
        "3.Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JveGlx25OB7H",
        "colab": {}
      },
      "source": [
        "def prediction(x, w, b):\n",
        "    \n",
        "    xw_matmul = tf.matmul(x, w)\n",
        "    y = tf.add(xw_matmul, b)\n",
        "    \n",
        "    return y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TL1hIwf_OB7M"
      },
      "source": [
        "4.Loss (Cost) Function [Mean square error]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8VSWPiGXOB7P",
        "colab": {}
      },
      "source": [
        "def loss(y_actual, y_predicted):\n",
        "    \n",
        "    diff = y_actual - y_predicted\n",
        "    sqr = tf.square(diff)\n",
        "    avg = tf.reduce_mean(sqr)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jzG85FUlOB7U"
      },
      "source": [
        "5.GradientDescent Optimizer to minimize Loss [GradientDescentOptimizer]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cj802w-3OB7X",
        "colab": {}
      },
      "source": [
        "def train(x, y_actual, w, b, learning_rate=0.01):\n",
        "    \n",
        "    #Record mathematical operations on 'tape' to calculate loss\n",
        "    with tf.GradientTape() as t:\n",
        "        \n",
        "        t.watch([w,b])\n",
        "        \n",
        "        current_prediction = prediction(x, w, b)\n",
        "        current_loss = loss(y_actual, current_prediction)\n",
        "    \n",
        "    #Calculate Gradients for Loss with respect to Weights and Bias\n",
        "    dw, db = t.gradient(current_loss,[w, b])\n",
        "    \n",
        "    #Update Weights and Bias\n",
        "    w = w - learning_rate*dw\n",
        "    b = b - learning_rate*db\n",
        "    \n",
        "    return w, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xSypb_u8OB7e"
      },
      "source": [
        "## Execute the Graph for 100 epochs and observe the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVvgj7eQOB7f",
        "outputId": "9cf392bc-4e7f-4b6d-9045-0a1a0b79157b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "for i in range(100):\n",
        "    \n",
        "    w, b = train(X_train_transform, np.array(train_y), w, b)\n",
        "    print('Current Loss on iteration', i, loss(np.array(train_y), prediction(X_train_transform, w, b)).numpy())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Loss on iteration 0 7738.2944\n",
            "Current Loss on iteration 1 7567.6377\n",
            "Current Loss on iteration 2 7403.96\n",
            "Current Loss on iteration 3 7246.9775\n",
            "Current Loss on iteration 4 7096.416\n",
            "Current Loss on iteration 5 6952.012\n",
            "Current Loss on iteration 6 6813.5137\n",
            "Current Loss on iteration 7 6680.681\n",
            "Current Loss on iteration 8 6553.281\n",
            "Current Loss on iteration 9 6431.092\n",
            "Current Loss on iteration 10 6313.901\n",
            "Current Loss on iteration 11 6201.502\n",
            "Current Loss on iteration 12 6093.7007\n",
            "Current Loss on iteration 13 5990.3086\n",
            "Current Loss on iteration 14 5891.1455\n",
            "Current Loss on iteration 15 5796.0386\n",
            "Current Loss on iteration 16 5704.821\n",
            "Current Loss on iteration 17 5617.3345\n",
            "Current Loss on iteration 18 5533.426\n",
            "Current Loss on iteration 19 5452.949\n",
            "Current Loss on iteration 20 5375.764\n",
            "Current Loss on iteration 21 5301.736\n",
            "Current Loss on iteration 22 5230.7354\n",
            "Current Loss on iteration 23 5162.639\n",
            "Current Loss on iteration 24 5097.327\n",
            "Current Loss on iteration 25 5034.6875\n",
            "Current Loss on iteration 26 4974.6094\n",
            "Current Loss on iteration 27 4916.9883\n",
            "Current Loss on iteration 28 4861.724\n",
            "Current Loss on iteration 29 4808.72\n",
            "Current Loss on iteration 30 4757.884\n",
            "Current Loss on iteration 31 4709.1265\n",
            "Current Loss on iteration 32 4662.364\n",
            "Current Loss on iteration 33 4617.5127\n",
            "Current Loss on iteration 34 4574.497\n",
            "Current Loss on iteration 35 4533.24\n",
            "Current Loss on iteration 36 4493.671\n",
            "Current Loss on iteration 37 4455.7197\n",
            "Current Loss on iteration 38 4419.32\n",
            "Current Loss on iteration 39 4384.41\n",
            "Current Loss on iteration 40 4350.9272\n",
            "Current Loss on iteration 41 4318.8145\n",
            "Current Loss on iteration 42 4288.014\n",
            "Current Loss on iteration 43 4258.4736\n",
            "Current Loss on iteration 44 4230.1416\n",
            "Current Loss on iteration 45 4202.968\n",
            "Current Loss on iteration 46 4176.906\n",
            "Current Loss on iteration 47 4151.9097\n",
            "Current Loss on iteration 48 4127.936\n",
            "Current Loss on iteration 49 4104.942\n",
            "Current Loss on iteration 50 4082.889\n",
            "Current Loss on iteration 51 4061.7375\n",
            "Current Loss on iteration 52 4041.4512\n",
            "Current Loss on iteration 53 4021.9944\n",
            "Current Loss on iteration 54 4003.3328\n",
            "Current Loss on iteration 55 3985.4348\n",
            "Current Loss on iteration 56 3968.2688\n",
            "Current Loss on iteration 57 3951.8044\n",
            "Current Loss on iteration 58 3936.0137\n",
            "Current Loss on iteration 59 3920.8684\n",
            "Current Loss on iteration 60 3906.3428\n",
            "Current Loss on iteration 61 3892.411\n",
            "Current Loss on iteration 62 3879.0488\n",
            "Current Loss on iteration 63 3866.2332\n",
            "Current Loss on iteration 64 3853.9417\n",
            "Current Loss on iteration 65 3842.1523\n",
            "Current Loss on iteration 66 3830.8457\n",
            "Current Loss on iteration 67 3820.0005\n",
            "Current Loss on iteration 68 3809.5996\n",
            "Current Loss on iteration 69 3799.624\n",
            "Current Loss on iteration 70 3790.0552\n",
            "Current Loss on iteration 71 3780.8784\n",
            "Current Loss on iteration 72 3772.077\n",
            "Current Loss on iteration 73 3763.6353\n",
            "Current Loss on iteration 74 3755.5383\n",
            "Current Loss on iteration 75 3747.7727\n",
            "Current Loss on iteration 76 3740.3247\n",
            "Current Loss on iteration 77 3733.181\n",
            "Current Loss on iteration 78 3726.3296\n",
            "Current Loss on iteration 79 3719.758\n",
            "Current Loss on iteration 80 3713.4548\n",
            "Current Loss on iteration 81 3707.4097\n",
            "Current Loss on iteration 82 3701.6116\n",
            "Current Loss on iteration 83 3696.0503\n",
            "Current Loss on iteration 84 3690.7168\n",
            "Current Loss on iteration 85 3685.6008\n",
            "Current Loss on iteration 86 3680.6943\n",
            "Current Loss on iteration 87 3675.9883\n",
            "Current Loss on iteration 88 3671.4749\n",
            "Current Loss on iteration 89 3667.1455\n",
            "Current Loss on iteration 90 3662.9937\n",
            "Current Loss on iteration 91 3659.0105\n",
            "Current Loss on iteration 92 3655.1904\n",
            "Current Loss on iteration 93 3651.527\n",
            "Current Loss on iteration 94 3648.0127\n",
            "Current Loss on iteration 95 3644.6423\n",
            "Current Loss on iteration 96 3641.4097\n",
            "Current Loss on iteration 97 3638.3088\n",
            "Current Loss on iteration 98 3635.3352\n",
            "Current Loss on iteration 99 3632.4824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9smwOW-1OB7k",
        "outputId": "24c53da1-7766-45c2-d794-724a076d5aa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_transform.dtype\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9JuLI6bSOB7n",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DOL2ncA1OB7q"
      },
      "source": [
        "### Get the shapes and values of W and b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZGvtyTeuOB7r",
        "outputId": "48584456-d9e9-4cce-ad95-1eb56a43c8e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(w)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[5.561033 ]\n",
            " [5.5293627]\n",
            " [5.5900593]\n",
            " [1.4008764]], shape=(4, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhDtOv5UOB7x",
        "outputId": "bf0dea5e-e4b2-4802-dedb-955670f4a934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(w.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJRBuqXhOB7_"
      },
      "source": [
        "### Linear Classification using Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdSJckEXgBS5",
        "colab_type": "code",
        "outputId": "daeb986e-6e35-4818-b108-f59e654c73d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(b)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([56.00991], shape=(1,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv0JzqBYgFE4",
        "colab_type": "code",
        "outputId": "eb2ef2f0-fdec-4d08-c7c1-4a033ac5a09b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(b.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8GoNTWXAOB8C"
      },
      "source": [
        "### Building the simple Neural Network in Keras with one neuron in the dense hidden layer.\n",
        "#### Use Mean square error as loss function and sgd as optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zpeL5rCTOB8D",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwqnAbMttju3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize Sequential Graph (model)\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "#Add Dense layer for prediction - Keras declares weights and bias automatically\n",
        "model.add(tf.keras.layers.Dense(1, input_shape=(4,)))\n",
        "\n",
        "#Compile the model - add Loss and Gradient Descent optimizer\n",
        "model.compile(optimizer='sgd', loss='mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wt-HYFMEOB8G"
      },
      "source": [
        "### Execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "66JGJt7GOB8H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "622b8c24-c8c4-4f39-9c20-ee1c73143f64"
      },
      "source": [
        "model.fit(X_train_transform, np.array(train_y), epochs=100)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "800/800 [==============================] - 0s 395us/sample - loss: 6202.1837\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 0s 36us/sample - loss: 4242.6810\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 0s 33us/sample - loss: 3492.6941\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 0s 34us/sample - loss: 3174.2444\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 0s 35us/sample - loss: 3008.1916\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 0s 31us/sample - loss: 2899.6543\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 0s 34us/sample - loss: 2811.0984\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 0s 34us/sample - loss: 2734.4314\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 0s 40us/sample - loss: 2661.8218\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 2591.8447\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 0s 35us/sample - loss: 2524.3134\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 0s 33us/sample - loss: 2458.7363\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 0s 33us/sample - loss: 2393.0679\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 0s 32us/sample - loss: 2330.3588\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 2269.1045\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 0s 35us/sample - loss: 2209.5894\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 0s 34us/sample - loss: 2151.7555\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 0s 34us/sample - loss: 2095.5911\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 0s 36us/sample - loss: 2040.7713\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 0s 36us/sample - loss: 1987.2066\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 0s 34us/sample - loss: 1935.5658\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 0s 36us/sample - loss: 1884.5748\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 0s 42us/sample - loss: 1834.7706\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 0s 41us/sample - loss: 1787.9789\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 0s 36us/sample - loss: 1741.6270\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 0s 41us/sample - loss: 1695.1768\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 0s 39us/sample - loss: 1650.2119\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 0s 36us/sample - loss: 1607.8365\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 1566.1548\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 0s 38us/sample - loss: 1523.5970\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 0s 42us/sample - loss: 1484.1154\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 0s 44us/sample - loss: 1445.8821\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 0s 42us/sample - loss: 1407.7290\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 1370.5327\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 0s 39us/sample - loss: 1334.6296\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 0s 35us/sample - loss: 1300.1345\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 0s 34us/sample - loss: 1265.4196\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 0s 34us/sample - loss: 1232.8082\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 0s 33us/sample - loss: 1200.2281\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 0s 34us/sample - loss: 1170.0372\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 0s 35us/sample - loss: 1138.0910\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 0s 34us/sample - loss: 1109.1839\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 0s 32us/sample - loss: 1079.7047\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 0s 31us/sample - loss: 1050.9460\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 1023.8791\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 996.9757\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 971.4023\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 945.4518\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 0s 34us/sample - loss: 920.7085\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 0s 33us/sample - loss: 896.7215\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 0s 38us/sample - loss: 873.8885\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 0s 35us/sample - loss: 850.2881\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 0s 33us/sample - loss: 828.3682\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 0s 35us/sample - loss: 806.6583\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 785.2405\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 0s 39us/sample - loss: 764.6935\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 0s 35us/sample - loss: 744.7190\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 0s 40us/sample - loss: 725.3764\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 0s 39us/sample - loss: 706.3281\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 0s 36us/sample - loss: 687.8112\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 669.9097\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 652.5342\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 635.4427\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 0s 38us/sample - loss: 618.7437\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 0s 36us/sample - loss: 602.6162\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 0s 32us/sample - loss: 587.1484\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 0s 32us/sample - loss: 571.2866\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 556.8027\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 0s 42us/sample - loss: 542.0341\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 0s 31us/sample - loss: 527.9421\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 0s 40us/sample - loss: 513.9299\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 0s 40us/sample - loss: 500.5116\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 0s 36us/sample - loss: 487.6760\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 0s 38us/sample - loss: 474.6718\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 0s 42us/sample - loss: 462.4950\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 0s 35us/sample - loss: 450.3099\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 0s 39us/sample - loss: 438.3793\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 0s 46us/sample - loss: 426.8875\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 416.0660\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 0s 43us/sample - loss: 404.9565\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 0s 38us/sample - loss: 394.6969\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 0s 30us/sample - loss: 384.0509\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 0s 38us/sample - loss: 374.0758\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 0s 44us/sample - loss: 364.3761\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 354.7921\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 0s 35us/sample - loss: 345.5800\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 0s 43us/sample - loss: 336.4772\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 0s 35us/sample - loss: 327.8699\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 0s 56us/sample - loss: 319.1804\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 0s 39us/sample - loss: 310.7656\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 0s 34us/sample - loss: 302.9029\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 294.8457\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 0s 38us/sample - loss: 287.0866\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 0s 36us/sample - loss: 279.6697\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 0s 38us/sample - loss: 272.3664\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 0s 37us/sample - loss: 265.2045\n",
            "Epoch 97/100\n",
            "800/800 [==============================] - 0s 36us/sample - loss: 258.2823\n",
            "Epoch 98/100\n",
            "800/800 [==============================] - 0s 41us/sample - loss: 251.5514\n",
            "Epoch 99/100\n",
            "800/800 [==============================] - 0s 39us/sample - loss: 245.1609\n",
            "Epoch 100/100\n",
            "800/800 [==============================] - 0s 32us/sample - loss: 238.5533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff5f22b2ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FtcjU6QmkXVe",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxEqkQx6PpYW",
        "colab_type": "text"
      },
      "source": [
        "### Classification using Keras "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXHw4spfPpYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIy5eNS9PpYX",
        "colab_type": "text"
      },
      "source": [
        "### Load the given Iris data using pandas (Iris.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSUMCM4_PpYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d1f798b2-f54c-4ec7-b704-d3374fe2a627"
      },
      "source": [
        "datairis = pd.read_csv('/content/Iris-2.csv')\n",
        "datairis.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWWq9FLRPpYZ",
        "colab_type": "text"
      },
      "source": [
        "### Splitting the data into feature set and target set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmYK9pStPpYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = datairis.drop(columns=['Id','Species'])\n",
        "y = datairis['Species']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Onm8vSLKPpYa",
        "colab_type": "text"
      },
      "source": [
        "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGvaTkF-PpYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = pd.get_dummies(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDA4XAn3PpYb",
        "colab_type": "text"
      },
      "source": [
        "### Divide the dataset into Training and test (70:30)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0exUsmC_PpYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un40VLElPpYc",
        "colab_type": "text"
      },
      "source": [
        "### Model\n",
        "Build the model with following layers: <br>\n",
        "1. First dense layer with 10 neurons with input shape 4 (according to the feature set) <br>\n",
        "2. Second Dense layer with 8 neurons <br>\n",
        "3. Output layer with 3 neurons with softmax activation (output layer, 3 neurons as we have 3 classes) <br>\n",
        "4. Use SGD and categorical_crossentropy loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmTr922VPpYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6Kc69QhPpYd",
        "colab_type": "text"
      },
      "source": [
        "### Fitting the model and predicting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DfeL0TsPpYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h6GBSH6Md61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(10,input_shape=(4,),  activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(8,input_shape=(4,),  activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(3,input_shape=(4,),  activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzfALR1kPpYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRP_5VwFPpYf",
        "colab_type": "text"
      },
      "source": [
        "### Report Accuracy of the predicted values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLDIdQeKPpYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j-B3V88sFlB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "acd7305b-d0de-46bf-d625-d70acb45fbed"
      },
      "source": [
        "model.fit(np.array(X_train),np.array(y_train),          \n",
        "          epochs=100,\n",
        "          batch_size=20)\n",
        "model.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "105/105 [==============================] - 0s 161us/sample - loss: 0.4125 - acc: 0.8286\n",
            "Epoch 2/100\n",
            "105/105 [==============================] - 0s 129us/sample - loss: 0.4332 - acc: 0.8286\n",
            "Epoch 3/100\n",
            "105/105 [==============================] - 0s 131us/sample - loss: 0.4067 - acc: 0.8476\n",
            "Epoch 4/100\n",
            "105/105 [==============================] - 0s 136us/sample - loss: 0.4018 - acc: 0.8571\n",
            "Epoch 5/100\n",
            "105/105 [==============================] - 0s 129us/sample - loss: 0.4241 - acc: 0.8381\n",
            "Epoch 6/100\n",
            "105/105 [==============================] - 0s 139us/sample - loss: 0.4044 - acc: 0.8571\n",
            "Epoch 7/100\n",
            "105/105 [==============================] - 0s 119us/sample - loss: 0.4092 - acc: 0.8571\n",
            "Epoch 8/100\n",
            "105/105 [==============================] - 0s 120us/sample - loss: 0.4030 - acc: 0.8762\n",
            "Epoch 9/100\n",
            "105/105 [==============================] - 0s 124us/sample - loss: 0.4232 - acc: 0.8476\n",
            "Epoch 10/100\n",
            "105/105 [==============================] - 0s 122us/sample - loss: 0.4372 - acc: 0.8476\n",
            "Epoch 11/100\n",
            "105/105 [==============================] - 0s 102us/sample - loss: 0.4102 - acc: 0.8476\n",
            "Epoch 12/100\n",
            "105/105 [==============================] - 0s 99us/sample - loss: 0.4069 - acc: 0.8476\n",
            "Epoch 13/100\n",
            "105/105 [==============================] - 0s 97us/sample - loss: 0.3919 - acc: 0.8571\n",
            "Epoch 14/100\n",
            "105/105 [==============================] - 0s 104us/sample - loss: 0.3917 - acc: 0.8667\n",
            "Epoch 15/100\n",
            "105/105 [==============================] - 0s 144us/sample - loss: 0.4012 - acc: 0.8571\n",
            "Epoch 16/100\n",
            "105/105 [==============================] - 0s 142us/sample - loss: 0.3928 - acc: 0.8952\n",
            "Epoch 17/100\n",
            "105/105 [==============================] - 0s 152us/sample - loss: 0.4028 - acc: 0.8381\n",
            "Epoch 18/100\n",
            "105/105 [==============================] - 0s 137us/sample - loss: 0.4042 - acc: 0.8857\n",
            "Epoch 19/100\n",
            "105/105 [==============================] - 0s 130us/sample - loss: 0.5041 - acc: 0.7333\n",
            "Epoch 20/100\n",
            "105/105 [==============================] - 0s 153us/sample - loss: 0.3989 - acc: 0.8667\n",
            "Epoch 21/100\n",
            "105/105 [==============================] - 0s 126us/sample - loss: 0.4361 - acc: 0.8286\n",
            "Epoch 22/100\n",
            "105/105 [==============================] - 0s 126us/sample - loss: 0.3943 - acc: 0.8952\n",
            "Epoch 23/100\n",
            "105/105 [==============================] - 0s 124us/sample - loss: 0.4370 - acc: 0.8476\n",
            "Epoch 24/100\n",
            "105/105 [==============================] - 0s 116us/sample - loss: 0.3904 - acc: 0.8476\n",
            "Epoch 25/100\n",
            "105/105 [==============================] - 0s 146us/sample - loss: 0.3977 - acc: 0.8571\n",
            "Epoch 26/100\n",
            "105/105 [==============================] - 0s 127us/sample - loss: 0.4093 - acc: 0.8667\n",
            "Epoch 27/100\n",
            "105/105 [==============================] - 0s 158us/sample - loss: 0.3947 - acc: 0.8667\n",
            "Epoch 28/100\n",
            "105/105 [==============================] - 0s 138us/sample - loss: 0.3933 - acc: 0.8762\n",
            "Epoch 29/100\n",
            "105/105 [==============================] - 0s 130us/sample - loss: 0.4009 - acc: 0.8476\n",
            "Epoch 30/100\n",
            "105/105 [==============================] - 0s 114us/sample - loss: 0.4016 - acc: 0.8952\n",
            "Epoch 31/100\n",
            "105/105 [==============================] - 0s 104us/sample - loss: 0.4139 - acc: 0.8286\n",
            "Epoch 32/100\n",
            "105/105 [==============================] - 0s 122us/sample - loss: 0.4074 - acc: 0.8190\n",
            "Epoch 33/100\n",
            "105/105 [==============================] - 0s 133us/sample - loss: 0.3860 - acc: 0.8667\n",
            "Epoch 34/100\n",
            "105/105 [==============================] - 0s 116us/sample - loss: 0.4164 - acc: 0.8571\n",
            "Epoch 35/100\n",
            "105/105 [==============================] - 0s 113us/sample - loss: 0.4001 - acc: 0.8381\n",
            "Epoch 36/100\n",
            "105/105 [==============================] - 0s 128us/sample - loss: 0.4456 - acc: 0.8095\n",
            "Epoch 37/100\n",
            "105/105 [==============================] - 0s 118us/sample - loss: 0.4149 - acc: 0.8286\n",
            "Epoch 38/100\n",
            "105/105 [==============================] - 0s 124us/sample - loss: 0.4184 - acc: 0.8476\n",
            "Epoch 39/100\n",
            "105/105 [==============================] - 0s 123us/sample - loss: 0.3915 - acc: 0.8571\n",
            "Epoch 40/100\n",
            "105/105 [==============================] - 0s 119us/sample - loss: 0.3990 - acc: 0.8476\n",
            "Epoch 41/100\n",
            "105/105 [==============================] - 0s 106us/sample - loss: 0.3976 - acc: 0.8286\n",
            "Epoch 42/100\n",
            "105/105 [==============================] - 0s 101us/sample - loss: 0.4322 - acc: 0.8190\n",
            "Epoch 43/100\n",
            "105/105 [==============================] - 0s 103us/sample - loss: 0.3988 - acc: 0.8571\n",
            "Epoch 44/100\n",
            "105/105 [==============================] - 0s 124us/sample - loss: 0.3921 - acc: 0.8762\n",
            "Epoch 45/100\n",
            "105/105 [==============================] - 0s 119us/sample - loss: 0.3909 - acc: 0.8762\n",
            "Epoch 46/100\n",
            "105/105 [==============================] - 0s 117us/sample - loss: 0.3984 - acc: 0.8667\n",
            "Epoch 47/100\n",
            "105/105 [==============================] - 0s 107us/sample - loss: 0.4004 - acc: 0.8476\n",
            "Epoch 48/100\n",
            "105/105 [==============================] - 0s 124us/sample - loss: 0.4121 - acc: 0.8476\n",
            "Epoch 49/100\n",
            "105/105 [==============================] - 0s 139us/sample - loss: 0.4239 - acc: 0.8381\n",
            "Epoch 50/100\n",
            "105/105 [==============================] - 0s 124us/sample - loss: 0.3978 - acc: 0.8381\n",
            "Epoch 51/100\n",
            "105/105 [==============================] - 0s 121us/sample - loss: 0.4349 - acc: 0.8476\n",
            "Epoch 52/100\n",
            "105/105 [==============================] - 0s 107us/sample - loss: 0.4094 - acc: 0.8571\n",
            "Epoch 53/100\n",
            "105/105 [==============================] - 0s 125us/sample - loss: 0.4177 - acc: 0.8762\n",
            "Epoch 54/100\n",
            "105/105 [==============================] - 0s 139us/sample - loss: 0.4098 - acc: 0.8571\n",
            "Epoch 55/100\n",
            "105/105 [==============================] - 0s 176us/sample - loss: 0.3946 - acc: 0.8762\n",
            "Epoch 56/100\n",
            "105/105 [==============================] - 0s 107us/sample - loss: 0.3927 - acc: 0.8667\n",
            "Epoch 57/100\n",
            "105/105 [==============================] - 0s 116us/sample - loss: 0.3862 - acc: 0.8952\n",
            "Epoch 58/100\n",
            "105/105 [==============================] - 0s 123us/sample - loss: 0.3875 - acc: 0.8857\n",
            "Epoch 59/100\n",
            "105/105 [==============================] - 0s 118us/sample - loss: 0.4351 - acc: 0.8571\n",
            "Epoch 60/100\n",
            "105/105 [==============================] - 0s 106us/sample - loss: 0.4022 - acc: 0.8571\n",
            "Epoch 61/100\n",
            "105/105 [==============================] - 0s 110us/sample - loss: 0.3904 - acc: 0.8667\n",
            "Epoch 62/100\n",
            "105/105 [==============================] - 0s 131us/sample - loss: 0.4355 - acc: 0.8667\n",
            "Epoch 63/100\n",
            "105/105 [==============================] - 0s 147us/sample - loss: 0.3909 - acc: 0.8952\n",
            "Epoch 64/100\n",
            "105/105 [==============================] - 0s 124us/sample - loss: 0.3881 - acc: 0.8762\n",
            "Epoch 65/100\n",
            "105/105 [==============================] - 0s 128us/sample - loss: 0.3934 - acc: 0.8667\n",
            "Epoch 66/100\n",
            "105/105 [==============================] - 0s 131us/sample - loss: 0.4031 - acc: 0.8381\n",
            "Epoch 67/100\n",
            "105/105 [==============================] - 0s 102us/sample - loss: 0.3924 - acc: 0.8857\n",
            "Epoch 68/100\n",
            "105/105 [==============================] - 0s 119us/sample - loss: 0.4027 - acc: 0.8476\n",
            "Epoch 69/100\n",
            "105/105 [==============================] - 0s 101us/sample - loss: 0.3902 - acc: 0.8762\n",
            "Epoch 70/100\n",
            "105/105 [==============================] - 0s 100us/sample - loss: 0.3995 - acc: 0.8476\n",
            "Epoch 71/100\n",
            "105/105 [==============================] - 0s 110us/sample - loss: 0.3984 - acc: 0.8857\n",
            "Epoch 72/100\n",
            "105/105 [==============================] - 0s 104us/sample - loss: 0.4002 - acc: 0.8571\n",
            "Epoch 73/100\n",
            "105/105 [==============================] - 0s 105us/sample - loss: 0.4057 - acc: 0.8381\n",
            "Epoch 74/100\n",
            "105/105 [==============================] - 0s 95us/sample - loss: 0.4167 - acc: 0.8095\n",
            "Epoch 75/100\n",
            "105/105 [==============================] - 0s 116us/sample - loss: 0.4139 - acc: 0.8571\n",
            "Epoch 76/100\n",
            "105/105 [==============================] - 0s 118us/sample - loss: 0.3839 - acc: 0.9048\n",
            "Epoch 77/100\n",
            "105/105 [==============================] - 0s 128us/sample - loss: 0.3964 - acc: 0.8571\n",
            "Epoch 78/100\n",
            "105/105 [==============================] - 0s 124us/sample - loss: 0.3797 - acc: 0.8571\n",
            "Epoch 79/100\n",
            "105/105 [==============================] - 0s 104us/sample - loss: 0.3947 - acc: 0.8571\n",
            "Epoch 80/100\n",
            "105/105 [==============================] - 0s 112us/sample - loss: 0.3990 - acc: 0.8476\n",
            "Epoch 81/100\n",
            "105/105 [==============================] - 0s 100us/sample - loss: 0.3788 - acc: 0.9048\n",
            "Epoch 82/100\n",
            "105/105 [==============================] - 0s 113us/sample - loss: 0.3835 - acc: 0.8857\n",
            "Epoch 83/100\n",
            "105/105 [==============================] - 0s 127us/sample - loss: 0.3959 - acc: 0.8667\n",
            "Epoch 84/100\n",
            "105/105 [==============================] - 0s 148us/sample - loss: 0.4007 - acc: 0.8571\n",
            "Epoch 85/100\n",
            "105/105 [==============================] - 0s 135us/sample - loss: 0.4045 - acc: 0.8571\n",
            "Epoch 86/100\n",
            "105/105 [==============================] - 0s 130us/sample - loss: 0.3979 - acc: 0.8571\n",
            "Epoch 87/100\n",
            "105/105 [==============================] - 0s 138us/sample - loss: 0.3942 - acc: 0.8762\n",
            "Epoch 88/100\n",
            "105/105 [==============================] - 0s 106us/sample - loss: 0.4263 - acc: 0.8476\n",
            "Epoch 89/100\n",
            "105/105 [==============================] - 0s 98us/sample - loss: 0.4259 - acc: 0.8381\n",
            "Epoch 90/100\n",
            "105/105 [==============================] - 0s 143us/sample - loss: 0.3926 - acc: 0.8762\n",
            "Epoch 91/100\n",
            "105/105 [==============================] - 0s 133us/sample - loss: 0.4120 - acc: 0.8476\n",
            "Epoch 92/100\n",
            "105/105 [==============================] - 0s 120us/sample - loss: 0.3884 - acc: 0.8667\n",
            "Epoch 93/100\n",
            "105/105 [==============================] - 0s 124us/sample - loss: 0.3770 - acc: 0.9143\n",
            "Epoch 94/100\n",
            "105/105 [==============================] - 0s 152us/sample - loss: 0.3835 - acc: 0.9048\n",
            "Epoch 95/100\n",
            "105/105 [==============================] - 0s 182us/sample - loss: 0.3896 - acc: 0.8571\n",
            "Epoch 96/100\n",
            "105/105 [==============================] - 0s 145us/sample - loss: 0.3755 - acc: 0.8952\n",
            "Epoch 97/100\n",
            "105/105 [==============================] - 0s 140us/sample - loss: 0.3811 - acc: 0.8667\n",
            "Epoch 98/100\n",
            "105/105 [==============================] - 0s 106us/sample - loss: 0.3770 - acc: 0.8857\n",
            "Epoch 99/100\n",
            "105/105 [==============================] - 0s 112us/sample - loss: 0.4098 - acc: 0.8476\n",
            "Epoch 100/100\n",
            "105/105 [==============================] - 0s 156us/sample - loss: 0.4668 - acc: 0.9048\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_3 (Batch multiple                  16        \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              multiple                  50        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              multiple                  88        \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             multiple                  27        \n",
            "=================================================================\n",
            "Total params: 181\n",
            "Trainable params: 173\n",
            "Non-trainable params: 8\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cjughkpQsfha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4da45aea-58f3-4fd8-c3b0-f8a93c3b9c14"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 0s 201us/sample - loss: 0.4174 - acc: 0.8000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4173935744497511, 0.8]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8zdoUVMsIBK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8d1d876-420c-4244-8494-d8efa829405e"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoVmFluBwGvb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9716092b-4781-4940-e34c-29c5f5768983"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoXcgU4ywLlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}