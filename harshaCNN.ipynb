{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HARSHACNNipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlsZNx-jANAU",
        "colab_type": "code",
        "outputId": "5ae30c93-a30a-425b-ad0a-47f280dd2f6f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#! pip install -q kaggle\n",
        "from google.colab import files\n",
        "#upload kaggle.jason file from your kaggle account(download to local machine)\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0498862d-e20c-4f0a-8e91-918eb4caf94a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0498862d-e20c-4f0a-8e91-918eb4caf94a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"harshavardhansarrabu\",\"key\":\"f90dff36c1517ab57ea0df60aac9d3f6\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76E1OR96ARNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "#Import necessary libraries\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from zipfile import ZipFile\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from keras import applications\n",
        "from keras.models import Sequential, Model \n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import backend as k \n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4uWb6x6AaNI",
        "colab_type": "code",
        "outputId": "b173c48c-5c74-4350-f4f2-d9e2aa60d33a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list\n",
        "!kaggle competitions download -c plant-seedlings-classification"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                      title                                               size  lastUpdated          downloadCount  \n",
            "-------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
            "rajeevw/ufcdata                                          UFC-Fight historical data from 1993 to 2019          3MB  2019-07-05 09:58:02          10980  \n",
            "gustavomodelli/forest-fires-in-brazil                    Forest Fires in Brazil                              31KB  2019-08-24 16:09:16          16279  \n",
            "tristan581/17k-apple-app-store-strategy-games            17K Mobile Strategy Games                            8MB  2019-08-26 08:22:16          13390  \n",
            "chirin/africa-economic-banking-and-systemic-crisis-data  Africa Economic, Banking and Systemic Crisis Data   14KB  2019-07-21 02:00:17           6010  \n",
            "akhilv11/border-crossing-entry-data                      Border Crossing Entry Data                           4MB  2019-08-21 14:51:34           6685  \n",
            "kapilverma/hindi-bible                                   Hindi Bible                                          5MB  2019-09-07 18:04:35            491  \n",
            "ruslankl/european-union-lgbt-survey-2012                 EU LGBT Survey                                     610KB  2019-07-19 11:15:25           2344  \n",
            "shuyangli94/food-com-recipes-and-user-interactions       Food.com Recipes and Interactions                  267MB  2019-11-08 01:18:21           4723  \n",
            "brkurzawa/us-breweries                                   US Breweries                                        76KB  2019-10-02 03:15:27           3260  \n",
            "pascalbliem/european-social-survey-ess-8-ed21-201617     European Social Survey (ESS) 8 ed2.1 (2016/17)      10MB  2019-09-29 07:30:37           1189  \n",
            "grikomsn/amazon-cell-phones-reviews                      Amazon Cell Phones Reviews                          10MB  2019-09-29 02:26:48           4355  \n",
            "srikantsahu/co2-and-ghg-emission-data                    CO2 and GHG emission data                           91KB  2019-09-26 20:10:59           2898  \n",
            "jojoker/singapore-airbnb                                 Singapore Airbnb                                   350KB  2019-09-25 22:05:44           3666  \n",
            "hmavrodiev/sofia-air-quality-dataset                     Sofia air quality dataset                            3GB  2019-09-14 05:48:09           2085  \n",
            "nitinsss/military-expenditure-of-countries-19602019      Military Spending of Countries (1960-2019)          55KB  2019-10-10 12:17:37           4743  \n",
            "valentynsichkar/traffic-signs-preprocessed               Traffic Signs Preprocessed                           4GB  2019-08-31 18:22:11           2071  \n",
            "hmavrodiev/london-bike-sharing-dataset                   London bike sharing dataset                        165KB  2019-10-10 12:49:37           5512  \n",
            "irinachuchueva/russian-wholesale-electricity-market      Russian Wholesale Electricity Market                 1MB  2019-10-09 08:20:57           1151  \n",
            "smid80/canadian-federal-election-results-timeseries      Canadian Federal Election Results (Timeseries)      18MB  2019-10-09 11:08:29           1088  \n",
            "mabusalah/brent-oil-prices                               Brent Oil Prices                                    38KB  2019-10-14 12:31:05           2736  \n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/5.13k [00:00<?, ?B/s]\n",
            "100% 5.13k/5.13k [00:00<00:00, 4.86MB/s]\n",
            "Downloading test.zip to /content\n",
            " 97% 83.0M/86.0M [00:01<00:00, 45.2MB/s]\n",
            "100% 86.0M/86.0M [00:01<00:00, 57.2MB/s]\n",
            "Downloading train.zip to /content\n",
            "100% 1.60G/1.60G [00:25<00:00, 52.8MB/s]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD4Gj-QhBoDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with ZipFile('/content/test.zip', 'r') as Data:\n",
        "  Data.extractall()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHdKjvnOCEqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with ZipFile('/content/train.zip', 'r') as Data:\n",
        "  Data.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or8-QT6tAdaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test=[]\n",
        "os.chdir('/content/test')\n",
        "import cv2\n",
        "for i in os.listdir():\n",
        "    dummy = cv2.imread(i)\n",
        "    dummy = cv2.resize(dummy,(128,128))\n",
        "    x_test.append(dummy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aMtqHmNA-c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "os.chdir('/content/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaCoO7RNBKuz",
        "colab_type": "code",
        "outputId": "d31b3ca5-a5e2-4711-a388-177399ba6a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in os.listdir():\n",
        "    print(i)\n",
        "    if (os.path.isdir(i)):\n",
        "            for j in os.listdir(i):\n",
        "                try:\n",
        "                    dummy = cv2.imread('/content/train/' + i + \"/\" + j)\n",
        "                    dummy = cv2.resize(dummy,(128,128))\n",
        "                    x_train.append(dummy)\n",
        "                    y_train.append(i)\n",
        "                except Exception as e:\n",
        "                    print(e)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Charlock\n",
            "Loose Silky-bent\n",
            "Common Chickweed\n",
            "Cleavers\n",
            "Fat Hen\n",
            "Sugar beet\n",
            "Shepherds Purse\n",
            "Common wheat\n",
            "Scentless Mayweed\n",
            "Small-flowered Cranesbill\n",
            "Maize\n",
            "Black-grass\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5sb1nckDgU2",
        "colab_type": "code",
        "outputId": "9573c422-3d00-452b-f448-89bad87caa17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu5REYlWD8EY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dum = pd.get_dummies(y_train)\n",
        "encoded_labels = dum\n",
        "y_train = dum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qASLKPzEslq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.array(y_train)\n",
        "x_train = np.array(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_haka19eEw2p",
        "colab_type": "code",
        "outputId": "521cf0f3-57ec-4b75-e0ab-31a09faecbc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train2, x_val, y_train2, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=2)\n",
        "print (len(x_train2))\n",
        "print (len(x_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3800\n",
            "950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6XqI5J1E1sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train2 = x_train2.reshape(x_train2.shape[0],128,128,3)\n",
        "x_val = x_val.reshape(x_val.shape[0],128,128,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgJ7-ei_E9yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Standardize the images\n",
        "x_train2 = x_train2/255.\n",
        "x_val = x_val/255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrzXOKY1FWeV",
        "colab_type": "code",
        "outputId": "bb18a9c1-799c-4943-80be-e35730c40342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print (x_train2.shape, x_val.shape)\n",
        "print (y_train2.shape, y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3800, 128, 128, 3) (950, 128, 128, 3)\n",
            "(3800, 12) (950, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYTY-48pFZK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import cifar10, mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import adam\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBMlg5qkKxd2",
        "colab_type": "code",
        "outputId": "42bb6c7d-c771-486e-ff4c-0e531de1e8a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize and Build the Model\n",
        "\n",
        "\n",
        "TRAIN = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "# Define the Type of Model\n",
        "model1 = Sequential()\n",
        "# 1st Conv Layer\n",
        "model1.add(BatchNormalization(input_shape = (128,128,3)))\n",
        "model1.add(Convolution2D(32, (3,3), activation ='relu', input_shape = (128, 128, 3)))\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "# 2nd Conv Layer\n",
        "model1.add(Convolution2D(32, 3, 3))\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "# Fully Connected Layer\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(128))\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "# Dense Layer\n",
        "model1.add(Dense(12))\n",
        "model1.add(Activation('softmax'))\n",
        "\n",
        "# Loss and Optimizer\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "# Train the model\n",
        "model1.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
        "              validation_data=(x_val, y_val))\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 4750 samples, validate on 950 samples\n",
            "Epoch 1/10\n",
            "4750/4750 [==============================] - 396s 83ms/step - loss: 13.8250 - acc: 0.1358 - val_loss: 13.8107 - val_acc: 0.1432\n",
            "Epoch 2/10\n",
            "4750/4750 [==============================] - 372s 78ms/step - loss: 13.8852 - acc: 0.1381 - val_loss: 4.7646 - val_acc: 0.1432\n",
            "Epoch 3/10\n",
            "4750/4750 [==============================] - 373s 79ms/step - loss: 3.3041 - acc: 0.1509 - val_loss: 2.4740 - val_acc: 0.0926\n",
            "Epoch 4/10\n",
            "4750/4750 [==============================] - 372s 78ms/step - loss: 1.5521 - acc: 0.5101 - val_loss: 2.4906 - val_acc: 0.0926\n",
            "Epoch 5/10\n",
            "4750/4750 [==============================] - 373s 78ms/step - loss: 0.3015 - acc: 0.9173 - val_loss: 2.4926 - val_acc: 0.0926\n",
            "Epoch 6/10\n",
            "4750/4750 [==============================] - 375s 79ms/step - loss: 0.0479 - acc: 0.9876 - val_loss: 2.4925 - val_acc: 0.0926\n",
            "Epoch 7/10\n",
            "4750/4750 [==============================] - 372s 78ms/step - loss: 0.0180 - acc: 0.9964 - val_loss: 2.4905 - val_acc: 0.0926\n",
            "Epoch 8/10\n",
            "4750/4750 [==============================] - 373s 78ms/step - loss: 0.0151 - acc: 0.9962 - val_loss: 2.4895 - val_acc: 0.0926\n",
            "Epoch 9/10\n",
            "4750/4750 [==============================] - 373s 78ms/step - loss: 0.0113 - acc: 0.9971 - val_loss: 2.4893 - val_acc: 0.0926\n",
            "Epoch 10/10\n",
            "4750/4750 [==============================] - 371s 78ms/step - loss: 0.0058 - acc: 0.9983 - val_loss: 2.4885 - val_acc: 0.0926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f55f4062f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9j8PkKQLJfN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "b4e2676a-6938-4907-b3f1-52f06eabd9c0"
      },
      "source": [
        "# Optimize the model\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "# Define Model\n",
        "model2 = Sequential()\n",
        "\n",
        "# 1st Conv Layer\n",
        "model2.add(Convolution2D(32, 3, 3, input_shape=(128, 128, 3)))\n",
        "model2.add(Activation('relu'))\n",
        "\n",
        "# 2nd Conv Layer\n",
        "model2.add(Convolution2D(32, 3, 3))\n",
        "model2.add(Activation('relu'))\n",
        "\n",
        "# Max Pooling\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "# Dropout\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "# Fully Connected Layer\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(128))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "# Dense Layer\n",
        "model2.add(Dense(12))\n",
        "model2.add(Activation('softmax'))\n",
        "\n",
        "# Loss and Optimizer\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model2.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
        "              validation_data=(x_val, y_val))\n",
        "    \n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(128, 128,...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 4750 samples, validate on 950 samples\n",
            "Epoch 1/10\n",
            "4750/4750 [==============================] - 264s 56ms/step - loss: 14.7796 - acc: 0.0825 - val_loss: 15.3574 - val_acc: 0.0442\n",
            "Epoch 2/10\n",
            "4750/4750 [==============================] - 274s 58ms/step - loss: 14.8610 - acc: 0.0779 - val_loss: 14.4554 - val_acc: 0.1032\n",
            "Epoch 3/10\n",
            "4750/4750 [==============================] - 275s 58ms/step - loss: 14.5606 - acc: 0.0966 - val_loss: 14.4554 - val_acc: 0.1032\n",
            "Epoch 4/10\n",
            "4750/4750 [==============================] - 276s 58ms/step - loss: 14.6251 - acc: 0.0926 - val_loss: 14.4554 - val_acc: 0.1032\n",
            "Epoch 5/10\n",
            "4750/4750 [==============================] - 279s 59ms/step - loss: 14.5529 - acc: 0.0971 - val_loss: 14.4554 - val_acc: 0.1032\n",
            "Epoch 6/10\n",
            "4750/4750 [==============================] - 255s 54ms/step - loss: 14.4825 - acc: 0.1015 - val_loss: 14.4554 - val_acc: 0.1032\n",
            "Epoch 7/10\n",
            "4750/4750 [==============================] - 248s 52ms/step - loss: 14.4893 - acc: 0.1011 - val_loss: 14.4554 - val_acc: 0.1032\n",
            "Epoch 8/10\n",
            "4750/4750 [==============================] - 247s 52ms/step - loss: 14.4825 - acc: 0.1015 - val_loss: 14.4554 - val_acc: 0.1032\n",
            "Epoch 9/10\n",
            "4750/4750 [==============================] - 248s 52ms/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4554 - val_acc: 0.1032\n",
            "Epoch 10/10\n",
            "4750/4750 [==============================] - 249s 52ms/step - loss: 14.5165 - acc: 0.0994 - val_loss: 14.4554 - val_acc: 0.1032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f55f3974a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk6lz2doCeBy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "47c4a8bd-d7dd-4e7b-ce64-cedf71ac877d"
      },
      "source": [
        "# Improving the model further\n",
        "\n",
        "model4 = Sequential()\n",
        "model4.add(BatchNormalization(input_shape = (128,128,3)))\n",
        "\n",
        "# First Layer\n",
        "model4.add(Convolution2D(32, (3,3), activation ='relu', input_shape = (128, 128, 3))) \n",
        "model4.add(MaxPooling2D(pool_size=2))\n",
        "model4.add(Dropout(0.8))\n",
        "\n",
        "#Second layer\n",
        "model4.add(Convolution2D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
        "model4.add(MaxPooling2D(pool_size=2))\n",
        "model4.add(Dropout(0.8))\n",
        "\n",
        "#Third layer\n",
        "model4.add(Convolution2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model4.add(MaxPooling2D(pool_size=2))\n",
        "model4.add(Dropout(0.8))\n",
        "\n",
        "#Fourth layer\n",
        "model4.add(Convolution2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
        "model4.add(MaxPooling2D(pool_size=2))\n",
        "model4.add(Dropout(0.8))\n",
        "model4.add(Flatten()) \n",
        "\n",
        "# fully connected layer\n",
        "model4.add(Dense(units=128,activation = 'relu'))\n",
        "\n",
        "model4.add(Dense(units = 64, activation = 'relu'))\n",
        "model4.add(Dropout(0.3))\n",
        "\n",
        "model4.add(Dense(units = 32, activation = 'relu'))\n",
        "model4.add(Dropout(0.3))\n",
        "\n",
        "model4.add(Dense(units = 12, activation = 'softmax')) \n",
        "\n",
        "optimizer = adam(lr=0.001)\n",
        "model4.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
        "\n",
        "batch_size = 64\n",
        "nb_epochs = 10\n",
        "history = model4.fit(x_train,y_train,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_val,y_val),\n",
        "                    verbose = 1,\n",
        "                    initial_epoch=0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 4750 samples, validate on 950 samples\n",
            "Epoch 1/20\n",
            "4750/4750 [==============================] - 263s 55ms/step - loss: 2.8216 - acc: 0.1181 - val_loss: 2.4544 - val_acc: 0.1432\n",
            "Epoch 2/20\n",
            "4750/4750 [==============================] - 261s 55ms/step - loss: 2.4483 - acc: 0.1326 - val_loss: 2.4346 - val_acc: 0.1432\n",
            "Epoch 3/20\n",
            "4750/4750 [==============================] - 259s 54ms/step - loss: 2.4323 - acc: 0.1341 - val_loss: 2.4250 - val_acc: 0.1432\n",
            "Epoch 4/20\n",
            "4750/4750 [==============================] - 259s 54ms/step - loss: 2.4230 - acc: 0.1358 - val_loss: 2.4197 - val_acc: 0.1432\n",
            "Epoch 5/20\n",
            "4750/4750 [==============================] - 260s 55ms/step - loss: 2.4216 - acc: 0.1373 - val_loss: 2.4188 - val_acc: 0.1432\n",
            "Epoch 6/20\n",
            "4750/4750 [==============================] - 260s 55ms/step - loss: 2.4223 - acc: 0.1364 - val_loss: 2.4185 - val_acc: 0.1432\n",
            "Epoch 7/20\n",
            "4750/4750 [==============================] - 259s 55ms/step - loss: 2.4188 - acc: 0.1339 - val_loss: 2.4180 - val_acc: 0.1432\n",
            "Epoch 8/20\n",
            "4750/4750 [==============================] - 258s 54ms/step - loss: 2.4172 - acc: 0.1364 - val_loss: 2.4180 - val_acc: 0.1432\n",
            "Epoch 9/20\n",
            "4750/4750 [==============================] - 257s 54ms/step - loss: 2.4172 - acc: 0.1366 - val_loss: 2.4183 - val_acc: 0.1432\n",
            "Epoch 10/20\n",
            "4750/4750 [==============================] - 259s 54ms/step - loss: 2.4188 - acc: 0.1373 - val_loss: 2.4181 - val_acc: 0.1432\n",
            "Epoch 11/20\n",
            "4750/4750 [==============================] - 259s 54ms/step - loss: 2.4177 - acc: 0.1381 - val_loss: 2.4184 - val_acc: 0.1432\n",
            "Epoch 12/20\n",
            "4750/4750 [==============================] - 260s 55ms/step - loss: 2.4207 - acc: 0.1337 - val_loss: 2.4182 - val_acc: 0.1432\n",
            "Epoch 13/20\n",
            "4750/4750 [==============================] - 261s 55ms/step - loss: 2.4178 - acc: 0.1364 - val_loss: 2.4184 - val_acc: 0.1432\n",
            "Epoch 14/20\n",
            "4750/4750 [==============================] - 258s 54ms/step - loss: 2.4172 - acc: 0.1356 - val_loss: 2.4182 - val_acc: 0.1432\n",
            "Epoch 15/20\n",
            "4750/4750 [==============================] - 258s 54ms/step - loss: 2.4177 - acc: 0.1366 - val_loss: 2.4185 - val_acc: 0.1432\n",
            "Epoch 16/20\n",
            "4750/4750 [==============================] - 260s 55ms/step - loss: 2.4170 - acc: 0.1371 - val_loss: 2.4183 - val_acc: 0.1432\n",
            "Epoch 17/20\n",
            "4750/4750 [==============================] - 258s 54ms/step - loss: 2.4174 - acc: 0.1377 - val_loss: 2.4185 - val_acc: 0.1432\n",
            "Epoch 18/20\n",
            "4750/4750 [==============================] - 259s 55ms/step - loss: 2.4170 - acc: 0.1381 - val_loss: 2.4185 - val_acc: 0.1432\n",
            "Epoch 19/20\n",
            "4750/4750 [==============================] - 258s 54ms/step - loss: 2.4167 - acc: 0.1377 - val_loss: 2.4185 - val_acc: 0.1432\n",
            "Epoch 20/20\n",
            "4750/4750 [==============================] - 257s 54ms/step - loss: 2.4151 - acc: 0.1385 - val_loss: 2.4182 - val_acc: 0.1432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdZwYVpSNZII",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "f110601b-5536-4b7a-9453-7da552ca58fc"
      },
      "source": [
        "# Improving the model further\n",
        "\n",
        "model4 = Sequential()\n",
        "model4.add(BatchNormalization(input_shape = (128,128,3)))\n",
        "\n",
        "# First Layer\n",
        "model4.add(Convolution2D(32, (3,3), activation ='relu', input_shape = (128, 128, 3))) \n",
        "model4.add(MaxPooling2D(pool_size=2))\n",
        "model4.add(Dropout(0.8))\n",
        "\n",
        "#Second layer\n",
        "model4.add(Convolution2D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
        "model4.add(MaxPooling2D(pool_size=2))\n",
        "model4.add(Dropout(0.8))\n",
        "\n",
        "#Third layer\n",
        "model4.add(Convolution2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model4.add(MaxPooling2D(pool_size=2))\n",
        "model4.add(Dropout(0.8))\n",
        "\n",
        "#Fourth layer\n",
        "model4.add(Convolution2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
        "model4.add(MaxPooling2D(pool_size=2))\n",
        "model4.add(Dropout(0.8))\n",
        "model4.add(Flatten()) \n",
        "\n",
        "# fully connected layer\n",
        "model4.add(Dense(units=128,activation = 'relu'))\n",
        "\n",
        "model4.add(Dense(units = 64, activation = 'relu'))\n",
        "model4.add(Dropout(0.3))\n",
        "\n",
        "model4.add(Dense(units = 32, activation = 'relu'))\n",
        "model4.add(Dropout(0.3))\n",
        "\n",
        "model4.add(Dense(units = 12, activation = 'softmax')) \n",
        "\n",
        "optimizer = adam(lr=0.001)\n",
        "model4.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
        "\n",
        "batch_size = 64\n",
        "nb_epochs = 10\n",
        "history = model4.fit(x_train,y_train,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_val,y_val),\n",
        "                    verbose = 1,\n",
        "                    initial_epoch=0)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Train on 4750 samples, validate on 950 samples\n",
            "Epoch 1/20\n",
            "4750/4750 [==============================] - 262s 55ms/step - loss: 2.9604 - acc: 0.1084 - val_loss: 2.4655 - val_acc: 0.1316\n",
            "Epoch 2/20\n",
            "4750/4750 [==============================] - 262s 55ms/step - loss: 2.4572 - acc: 0.1225 - val_loss: 2.4492 - val_acc: 0.1316\n",
            "Epoch 3/20\n",
            "4750/4750 [==============================] - 263s 55ms/step - loss: 2.4353 - acc: 0.1379 - val_loss: 2.4364 - val_acc: 0.1316\n",
            "Epoch 4/20\n",
            "4750/4750 [==============================] - 262s 55ms/step - loss: 2.4297 - acc: 0.1398 - val_loss: 2.4291 - val_acc: 0.1316\n",
            "Epoch 5/20\n",
            "4750/4750 [==============================] - 264s 56ms/step - loss: 2.4169 - acc: 0.1429 - val_loss: 2.4257 - val_acc: 0.1316\n",
            "Epoch 6/20\n",
            "4750/4750 [==============================] - 271s 57ms/step - loss: 2.4014 - acc: 0.1539 - val_loss: 2.4246 - val_acc: 0.1316\n",
            "Epoch 7/20\n",
            "4750/4750 [==============================] - 269s 57ms/step - loss: 2.3827 - acc: 0.1636 - val_loss: 2.4257 - val_acc: 0.1316\n",
            "Epoch 8/20\n",
            "4750/4750 [==============================] - 267s 56ms/step - loss: 2.3452 - acc: 0.1844 - val_loss: 2.4369 - val_acc: 0.1316\n",
            "Epoch 9/20\n",
            "4750/4750 [==============================] - 265s 56ms/step - loss: 2.3223 - acc: 0.1876 - val_loss: 2.4563 - val_acc: 0.1316\n",
            "Epoch 10/20\n",
            "4750/4750 [==============================] - 267s 56ms/step - loss: 2.2857 - acc: 0.2053 - val_loss: 2.5091 - val_acc: 0.1316\n",
            "Epoch 11/20\n",
            "4750/4750 [==============================] - 266s 56ms/step - loss: 2.2465 - acc: 0.2078 - val_loss: 2.5878 - val_acc: 0.1316\n",
            "Epoch 12/20\n",
            "4750/4750 [==============================] - 273s 58ms/step - loss: 2.2135 - acc: 0.2328 - val_loss: 2.7276 - val_acc: 0.0968\n",
            "Epoch 13/20\n",
            "4750/4750 [==============================] - 272s 57ms/step - loss: 2.1571 - acc: 0.2434 - val_loss: 2.8720 - val_acc: 0.0968\n",
            "Epoch 14/20\n",
            "4750/4750 [==============================] - 267s 56ms/step - loss: 2.0526 - acc: 0.2777 - val_loss: 2.8735 - val_acc: 0.1316\n",
            "Epoch 15/20\n",
            "4750/4750 [==============================] - 268s 56ms/step - loss: 1.9760 - acc: 0.3179 - val_loss: 2.9400 - val_acc: 0.1316\n",
            "Epoch 16/20\n",
            "4750/4750 [==============================] - 265s 56ms/step - loss: 1.8703 - acc: 0.3436 - val_loss: 2.9712 - val_acc: 0.1316\n",
            "Epoch 17/20\n",
            "4750/4750 [==============================] - 263s 55ms/step - loss: 1.8639 - acc: 0.3457 - val_loss: 3.0286 - val_acc: 0.1316\n",
            "Epoch 18/20\n",
            "4750/4750 [==============================] - 263s 55ms/step - loss: 1.7863 - acc: 0.3644 - val_loss: 3.2060 - val_acc: 0.1316\n",
            "Epoch 19/20\n",
            "4750/4750 [==============================] - 261s 55ms/step - loss: 1.7699 - acc: 0.3731 - val_loss: 3.2349 - val_acc: 0.1316\n",
            "Epoch 20/20\n",
            "4750/4750 [==============================] - 262s 55ms/step - loss: 1.7704 - acc: 0.3676 - val_loss: 3.2292 - val_acc: 0.1316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KIze6i_3FSl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "32cb439d-7a3e-46fd-c6cb-6f2d6b69c76a"
      },
      "source": [
        "# Accuracy for Train data using each Model built\n",
        "\n",
        "# Model1\n",
        "print (\"Accuracy of Model1 is\",model1.evaluate(x_train,y_train));\n",
        "\n",
        "# Model2\n",
        "print (\"Accuracy of Model2 is\",model2.evaluate(x_train,y_train));\n",
        "\n",
        "# Model3\n",
        "print (\"Accuracy of Model3 is\",model3.evaluate(x_train,y_train));\n",
        "\n",
        "# Model4\n",
        "print (\"Accuracy of Model4 is\",model4.evaluate(x_train,y_train));\n",
        "\n",
        "# Inference:\n",
        "# Model3 gives a better accuracy of over 99% of all the other models\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4750/4750 [==============================] - 65s 14ms/step\n",
            "Accuracy of Model1 is [0.004648966988383204, 0.9987368421052631]\n",
            "4750/4750 [==============================] - 51s 11ms/step\n",
            "Accuracy of Model2 is [14.50628586457905, 0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-fd72a1482be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Model3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy of Model3 is\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Model4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model3' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYytpWYA3G2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}